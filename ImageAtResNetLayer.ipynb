{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "demo.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMlfYy0yqIrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8df5f41d-fa64-4254-980d-615718fd6be9"
      },
      "source": [
        "!pip install pytorchvis"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorchvis\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/ce/bd41fdd56288465d7081bce6c9b458adb0a5696a032c9633f4241684fafd/pytorchvis-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: pytorchvis\n",
            "Successfully installed pytorchvis-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQE2YvqIoACP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from pytorchvis.visualize_layers import VisualizeLayers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj2DO-NXoACe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the Pytorch model\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
        "print (model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQxvIZhatgsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "\n",
        "vis = VisualizeLayers(model,layers='conv')\n",
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbtOxsAXoACs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an object of VisualizeLayers and initialize it with the model and \n",
        "# the layers whose output you want to visualize\n",
        "#vis = VisualizeLayers(model,layers='conv')\n",
        "# load the input\n",
        "#x = torch.randn([1,3,224,224])\n",
        "# pass the input and get the output\n",
        "#with torch.no_grad():\n",
        "output = model(input_batch)\n",
        "# get the intermediate layers output which was passed during initialization\n",
        "interm_output = vis.get_interm_output()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ7bLNSUoAC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the featuremap of the layer which you want, to see what are the layers\n",
        "# saved simply call vis.get_saved_layer_names\n",
        "output_layers=vis.get_saved_layer_names()\n",
        "output_layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pHOFoHxoADN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vis.plot_featuremaps(interm_output['conv1_conv_Conv2d'],name='fmaps',color_map='color',savefig=True, figsize = 128)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e_DKZzioADZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to plot the intermediate \n",
        "vis.plot_featuremaps(interm_output[output_layers[-1]],name='fmaps',color_map='gray',savefig=True, figsize=1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIfvTy1l2rec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "interm_output['conv1_conv_Conv2d']\n",
        "nImg = interm_output.numpy()\n",
        "nImg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjUWDaqqoADk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "to_pil = torchvision.transforms.ToPILImage()\n",
        "img = to_pil(interm_output['conv1_conv_Conv2d'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}